{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "090dcd93-d918-4230-838f-ca5b6a13f787",
   "metadata": {},
   "source": [
    "## Q1. What is hierarchical clustering, and how is it different from other clustering techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1914d23f-91e8-4caf-a004-409eebc32e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Approach:\n",
    "\n",
    "Hierarchical clustering can be either agglomerative (bottom-up) or divisive (top-down).\n",
    "Agglomerative hierarchical clustering starts by considering each data point as a single cluster and then iteratively merges the closest pairs of clusters until only one cluster remains.\n",
    "Divisive hierarchical clustering starts with all data points in one cluster and then recursively divides clusters until each data point is in its own cluster.\n",
    "Cluster Representation:\n",
    "\n",
    "Hierarchical clustering does not require the number of clusters to be specified beforehand. Instead, it produces a dendrogram that visualizes the hierarchical relationships between clusters.\n",
    "Other clustering techniques, such as K-means or DBSCAN, require the number of clusters to be specified as an input parameter.\n",
    "Flexibility:\n",
    "\n",
    "Hierarchical clustering is more flexible than partitioning-based algorithms because it can accommodate clusters of arbitrary shapes and sizes.\n",
    "Partitioning-based algorithms like K-means assume that clusters are convex and isotropic, which may not always be the case in real-world data.\n",
    "Interpretability:\n",
    "\n",
    "Hierarchical clustering provides a hierarchical representation of clusters, making it easier to interpret the relationships between clusters at different levels of granularity.\n",
    "Partitioning-based algorithms typically produce a flat partitioning of the data, which may be less interpretable, especially when dealing with complex datasets.\n",
    "Computational Complexity:\n",
    "\n",
    "Hierarchical clustering algorithms can be computationally expensive, especially for large datasets, because they consider all pairwise distances between data points.\n",
    "Partitioning-based algorithms like K-means are often more computationally efficient, particularly for large datasets, because they involve fewer pairwise distance calculations.\n",
    "Scalability:\n",
    "\n",
    "Hierarchical clustering algorithms may not be as scalable as partitioning-based algorithms, especially for very large datasets, due to their computational complexity.\n",
    "Partitioning-based algorithms like K-means can be more scalable and suitable for large-scale clustering tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08f12cb-65ee-439b-9930-65be781eb980",
   "metadata": {},
   "source": [
    "## Q2. What are the two main types of hierarchical clustering algorithms? Describe each in brief."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594d238c-22c6-4f36-893d-cbb33d186a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
